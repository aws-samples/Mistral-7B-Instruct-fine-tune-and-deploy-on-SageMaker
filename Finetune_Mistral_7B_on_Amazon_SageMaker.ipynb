{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877bf5e-dcb6-4377-94e5-06332ab32848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.38.1 datasets==2.17.1 peft==0.8.2 bitsandbytes==0.42.0 trl==0.7.11 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57a9b4",
   "metadata": {},
   "source": [
    "This notebook has been tested on Amazon SageMaker Notebook Instances with single GPU on ml.g5.2xlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73cac042-5399-46d3-bfde-2728a06fe450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 15011\n",
      "{'instruction': 'Given this paragraph, which highs school did Drake Maye attend?', 'context': 'Drake Maye was born on August 30, 2002, in Charlotte, North Carolina. He attended and played high school football for Myers Park High School in Charlotte, where he was named MaxPreps North Carolina player of the year. He was a four-star prospect and originally committed to Alabama before flipping to North Carolina.', 'response': 'Based on this text, Drake Maye attended Myers Park High School in Charlotte, North Carolina.', 'category': 'closed_qa'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "\n",
    "#For local testing the fine tuning code, we limit the dataset to 20 samples \n",
    "#dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\").select(range(20))\n",
    "\n",
    "print(f\"dataset size: {len(dataset)}\")\n",
    "print(dataset[randrange(len(dataset))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b382391-42b8-4393-8523-55057824e3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4914025056f24db28ad831c972f94555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/15011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "local_path = \"./dataset/dolly.hf\"\n",
    "dataset.save_to_disk(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31100935-9aec-4643-9447-9e9daf35d770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::70768*******:role/service-role/AmazonSageMaker-ExecutionRole-20191024T163188\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08165c6c-cf0b-45df-ab4a-7073b421b9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset uploaded to --- &gt; s3://sagemaker-us-east-1-70768*******/train/data/dolly.hf\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "\n",
    "s3_data_prefix = \"train/data/dolly.hf\"\n",
    "bucket = sagemaker_session_bucket  # bucket to house artifacts\n",
    "training_input_path = sess.upload_data(local_path, bucket, s3_data_prefix)\n",
    "print(f\"training dataset uploaded to --- &gt; {training_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6a529-2f76-4a97-bfd8-254c20239a18",
   "metadata": {},
   "source": [
    "### Training with SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbeac35c-38d8-4823-85a2-a05deb347e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "instance_type = 'ml.g5.4xlarge'  # instances type used for the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc690758-4303-4e16-a115-eccbed1a2f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{model_id.replace(\"/\", \"-\").lower()}'\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training/dolly.hf',    # path where sagemaker will save training dataset\n",
    "  'epochs': 1,                                      # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                 # batch size for training\n",
    "  'lr': 2e-5,                                       # learning rate used during training\n",
    "}\n",
    "metric=[\n",
    "    {\"Name\": \"loss\", \"Regex\": r\"'loss':\\s*([0-9.]+)\"},\n",
    "    {\"Name\": \"epoch\", \"Regex\": r\"'epoch':\\s*([0-9.]+)\"},\n",
    "]\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'train.py',      # train script\n",
    "    source_dir           = 'training',         # directory which includes all the files needed for training\n",
    "    metric_definitions   = metric,\n",
    "    instance_type        = instance_type,   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adb98352-f5b8-4f46-8631-0995f1f17ade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-mistralai-mistral-7b--2024-03-04-07-40-17-256\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "training_input_path = \"s3://sagemaker-us-east-1-70768*******/train/data\"\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c04245-ffd1-44af-a7af-20fdc9756ea1",
   "metadata": {},
   "source": [
    "### Download the model weight from SageMaker Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c841257-839e-4bf7-9708-0159a2d9f65b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-70768********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./results/training_job/model.tar.gz']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the training job name\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "training_job_name = 'huggingface-qlora-mistralai-mistral-7b--2024-03-04-07-40-17-256'\n",
    "print(sagemaker_session_bucket)\n",
    "key = f'{training_job_name}/output/model.tar.gz'\n",
    "\n",
    "# Download the output of the training job\n",
    "local_path = './results/training_job/'\n",
    "S3Downloader.download(f's3://{bucket}/{key}', local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42161f1c-5c05-4b24-9b21-11a609154645",
   "metadata": {},
   "source": [
    "### The deployable model artifact with huggingface safe tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f03e0d2-fee2-4222-9b89-a086e3d178b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# Specify the path to the tar.gz file\n",
    "tar_gz_file = local_path + \"model.tar.gz\"\n",
    "\n",
    "# Extract the contents of the tar.gz file\n",
    "with tarfile.open(tar_gz_file, 'r:gz') as tar:\n",
    "    tar.extractall('./results/training_job')  # Specify the directory where you want to extract the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8bae1f-5015-49c4-be96-ca319582b212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
